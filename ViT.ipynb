{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, RandomRotation, RandomCrop, ColorJitter, Normalize\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "def create_patches(images, n_patches):\n",
        "    n, c, h, w = images.shape\n",
        "\n",
        "    assert h == w\n",
        "\n",
        "    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
        "    patch_size = h // n_patches\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        for i in range(n_patches):\n",
        "            for j in range(n_patches):\n",
        "                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
        "                patches[idx, i * n_patches + j] = patch.flatten()\n",
        "    return patches\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, d, n_heads=2):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.d = d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
        "\n",
        "        d_head = int(d / n_heads)\n",
        "        self.q_mappings = nn.Linear(d, d)\n",
        "        self.k_mappings = nn.Linear(d, d)\n",
        "        self.v_mappings = nn.Linear(d, d)\n",
        "        self.d_head = d_head\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        batch_size, seq_length, _ = sequences.size()\n",
        "        head_dim = self.d // self.n_heads\n",
        "\n",
        "        q = self.q_mappings(sequences)\n",
        "        k = self.k_mappings(sequences)\n",
        "        v = self.v_mappings(sequences)\n",
        "\n",
        "        q = q.view(batch_size, seq_length, self.n_heads, head_dim).permute(0, 2, 1, 3)\n",
        "        k = k.view(batch_size, seq_length, self.n_heads, head_dim).permute(0, 2, 1, 3)\n",
        "        v = v.view(batch_size, seq_length, self.n_heads, head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        attention = self.softmax(torch.matmul(q, k.permute(0, 1, 3, 2)) / (head_dim ** 0.5))\n",
        "        output = torch.matmul(attention, v).permute(0, 2, 1, 3).contiguous().view(batch_size, seq_length, self.d)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class ViTBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, mlp_ratio=4):\n",
        "        super(ViTBlock, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.mhsa = MultiHeadSelfAttention(hidden_dim, n_heads)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, mlp_ratio * hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_ratio * hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mhsa(self.norm1(x))\n",
        "        out = x + out\n",
        "        out = out + self.mlp(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, chw, n_patches=7, n_blocks=4, hidden_dim=16, n_heads=2, output_dim=10):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "\n",
        "        self.chw = chw\n",
        "        self.n_patches = n_patches\n",
        "        self.n_blocks = n_blocks\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        assert chw[1] % n_patches == 0\n",
        "        assert chw[2] % n_patches == 0\n",
        "        self.patch_size = (chw[1] // n_patches, chw[2] // n_patches)\n",
        "\n",
        "        self.input_dim = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
        "        self.linear_mapper = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_dim))\n",
        "        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_dim), persistent=False)\n",
        "        self.blocks = nn.ModuleList([ViTBlock(hidden_dim, n_heads) for _ in range(n_blocks)])\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        n, c, h, w = images.shape\n",
        "        patches = create_patches(images, self.n_patches).to(self.positional_embeddings.device)\n",
        "        tokens = self.linear_mapper(patches)\n",
        "        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)\n",
        "        out = tokens + self.positional_embeddings.repeat(n, 1, 1)\n",
        "        for block in self.blocks:\n",
        "            out = block(out)\n",
        "        out = out[:, 0]\n",
        "        return self.mlp(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_positional_embeddings(sequence_length, d):\n",
        "    positions = torch.arange(sequence_length, dtype=torch.float32).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d, 2, dtype=torch.float32) * -(torch.log(torch.tensor(10000.0)) / d))\n",
        "    embeddings = torch.zeros(sequence_length, d)\n",
        "    embeddings[:, 0::2] = torch.sin(positions / div_term)\n",
        "    embeddings[:, 1::2] = torch.cos(positions / div_term)\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "\n",
        "def data_augmentation(images):\n",
        "    transform = nn.Sequential(\n",
        "        RandomRotation(10),\n",
        "        RandomCrop(28, padding=4),\n",
        "        ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "    )\n",
        "    augmented_images = []\n",
        "    for image in images:\n",
        "        augmented_images.append(transform(image))\n",
        "    return torch.stack(augmented_images)\n",
        "\n",
        "\n",
        "def train(model, train_loader, test_loader, optimizer, criterion, scheduler, device):\n",
        "    n_epochs = 30\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            x, y = batch\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = data_augmentation(x)  # Apply data augmentation\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * x.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        accuracy = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                x, y = batch\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                y_hat = model(x)\n",
        "                loss = criterion(y_hat, y)\n",
        "                test_loss += loss.item() * x.size(0)\n",
        "                _, predicted_labels = torch.max(y_hat, 1)\n",
        "                accuracy += (predicted_labels == y).sum().item()\n",
        "\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            accuracy /= len(test_loader.dataset)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "            scheduler.step(test_loss)\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = MNIST(root=\"./data\", train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = MNIST(root=\"./data\", train=False, transform=ToTensor(), download=True)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Create model\n",
        "model = VisionTransformer(chw=(1, 28, 28)).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, test_loader, optimizer, criterion, scheduler, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHJv2JJ50k3A",
        "outputId": "4f0b2ba0-ed37-4c97-8e33-45e3d2096210"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train Loss: 2.1635, Test Loss: 2.0296, Accuracy: 0.4228\n",
            "Epoch 2/30, Train Loss: 2.0531, Test Loss: 1.9152, Accuracy: 0.5475\n",
            "Epoch 3/30, Train Loss: 1.9659, Test Loss: 1.8262, Accuracy: 0.6411\n",
            "Epoch 4/30, Train Loss: 1.9064, Test Loss: 1.7825, Accuracy: 0.6789\n",
            "Epoch 5/30, Train Loss: 1.8549, Test Loss: 1.7299, Accuracy: 0.7329\n",
            "Epoch 6/30, Train Loss: 1.8167, Test Loss: 1.6904, Accuracy: 0.7715\n",
            "Epoch 7/30, Train Loss: 1.7851, Test Loss: 1.6685, Accuracy: 0.7935\n",
            "Epoch 8/30, Train Loss: 1.7588, Test Loss: 1.6451, Accuracy: 0.8198\n",
            "Epoch 9/30, Train Loss: 1.7369, Test Loss: 1.6358, Accuracy: 0.8263\n",
            "Epoch 10/30, Train Loss: 1.7203, Test Loss: 1.6117, Accuracy: 0.8501\n",
            "Epoch 11/30, Train Loss: 1.7102, Test Loss: 1.6126, Accuracy: 0.8495\n",
            "Epoch 12/30, Train Loss: 1.6997, Test Loss: 1.6187, Accuracy: 0.8433\n",
            "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 13/30, Train Loss: 1.6619, Test Loss: 1.5758, Accuracy: 0.8862\n",
            "Epoch 14/30, Train Loss: 1.6502, Test Loss: 1.5734, Accuracy: 0.8889\n",
            "Epoch 15/30, Train Loss: 1.6452, Test Loss: 1.5669, Accuracy: 0.8953\n",
            "Epoch 16/30, Train Loss: 1.6413, Test Loss: 1.5663, Accuracy: 0.8956\n",
            "Epoch 17/30, Train Loss: 1.6396, Test Loss: 1.5642, Accuracy: 0.8979\n",
            "Epoch 18/30, Train Loss: 1.6366, Test Loss: 1.5633, Accuracy: 0.8977\n",
            "Epoch 19/30, Train Loss: 1.6350, Test Loss: 1.5681, Accuracy: 0.8943\n",
            "Epoch 20/30, Train Loss: 1.6337, Test Loss: 1.5651, Accuracy: 0.8963\n",
            "Epoch 00020: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 21/30, Train Loss: 1.6307, Test Loss: 1.5614, Accuracy: 0.9008\n",
            "Epoch 22/30, Train Loss: 1.6284, Test Loss: 1.5597, Accuracy: 0.9019\n",
            "Epoch 23/30, Train Loss: 1.6302, Test Loss: 1.5603, Accuracy: 0.9012\n",
            "Epoch 24/30, Train Loss: 1.6283, Test Loss: 1.5598, Accuracy: 0.9024\n",
            "Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 25/30, Train Loss: 1.6299, Test Loss: 1.5591, Accuracy: 0.9031\n",
            "Epoch 26/30, Train Loss: 1.6280, Test Loss: 1.5590, Accuracy: 0.9031\n",
            "Epoch 27/30, Train Loss: 1.6292, Test Loss: 1.5587, Accuracy: 0.9035\n",
            "Epoch 28/30, Train Loss: 1.6267, Test Loss: 1.5589, Accuracy: 0.9033\n",
            "Epoch 29/30, Train Loss: 1.6283, Test Loss: 1.5587, Accuracy: 0.9033\n",
            "Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 30/30, Train Loss: 1.6282, Test Loss: 1.5587, Accuracy: 0.9035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Save the model\n",
        "    torch.save(model.state_dict(), 'model_weights.pth')\n",
        "    print(\"Model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ujBPSebSq4t",
        "outputId": "dfbef7d6-21e5-432e-d3e5-06e612f10379"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JUeHmfHKX02l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}